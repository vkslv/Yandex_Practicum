{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор локации для скважины"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, вы работаете в добывающей компании «ГлавРосГосНефть». Нужно решить, где бурить новую скважину.\n",
    "\n",
    "Вам предоставлены пробы нефти в трёх регионах: в каждом 10 000 месторождений, где измерили качество нефти и объём её запасов. Постройте модель машинного обучения, которая поможет определить регион, где добыча принесёт наибольшую прибыль. Проанализируйте возможную прибыль и риски техникой *Bootstrap.*\n",
    "\n",
    "Шаги для выбора локации:\n",
    "\n",
    "- В избранном регионе ищут месторождения, для каждого определяют значения признаков;\n",
    "- Строят модель и оценивают объём запасов;\n",
    "- Выбирают месторождения с самым высокими оценками значений. Количество месторождений зависит от бюджета компании и стоимости разработки одной скважины;\n",
    "- Прибыль равна суммарной прибыли отобранных месторождений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy.stats as st\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    gd0 = pd.read_csv(r'C:\\Users\\vk\\data_science\\data\\regions\\geo_data_0.csv')\n",
    "    gd1 = pd.read_csv(r'C:\\Users\\vk\\data_science\\data\\regions\\geo_data_1.csv')\n",
    "    gd2 = pd.read_csv(r'C:\\Users\\vk\\data_science\\data\\regions\\geo_data_2.csv')\n",
    "except:\n",
    "    gd0 = pd.read_csv(r'/datasets/geo_data_0.csv')\n",
    "    gd1 = pd.read_csv('/datasets/geo_data_1.csv')\n",
    "    gd2 = pd.read_csv('/datasets/geo_data_2.csv')\n",
    "\n",
    "gd0.info()\n",
    "print()\n",
    "gd1.info()\n",
    "print()\n",
    "gd2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Загружаем данные, выводим информацию по кажому `DataFrame` региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
      "\n",
      "      id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
      "\n",
      "      id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n"
     ]
    }
   ],
   "source": [
    "print(gd0.head())\n",
    "print()\n",
    "print(gd1.head())\n",
    "print()\n",
    "print(gd2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Выводим первые пять строк каждого `DataFrame` региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сумма дубликатов в geo_data_0: 0\n",
      "\n",
      "Сумма дубликатов в geo_data_1: 0\n",
      "\n",
      "Сумма дубликатов в geo_data_2: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Сумма дубликатов в geo_data_0:\", gd0.duplicated().sum())\n",
    "print()\n",
    "print(\"Сумма дубликатов в geo_data_1:\", gd1.duplicated().sum())\n",
    "print()\n",
    "print(\"Сумма дубликатов в geo_data_2:\", gd2.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Выводим кол-во дубликатов в `DataFrame` каждого региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        0.500419       0.250143       2.502647      92.500000\n",
      "std         0.871832       0.504433       3.248248      44.288691\n",
      "min        -1.408605      -0.848218     -12.088328       0.000000\n",
      "25%        -0.072580      -0.200881       0.287748      56.497507\n",
      "50%         0.502360       0.250252       2.515969      91.849972\n",
      "75%         1.073581       0.700646       4.715088     128.564089\n",
      "max         2.362331       1.343769      16.003790     185.364347\n",
      "\n",
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        1.141296      -4.796579       2.494541      68.825000\n",
      "std         8.965932       5.119872       1.703572      45.944423\n",
      "min       -31.609576     -26.358598      -0.018144       0.000000\n",
      "25%        -6.298551      -8.267985       1.000021      26.953261\n",
      "50%         1.153055      -4.813172       2.011479      57.085625\n",
      "75%         8.621015      -1.332816       3.999904     107.813044\n",
      "max        29.421755      18.734063       5.019721     137.945408\n",
      "\n",
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        0.002023      -0.002081       2.495128      95.000000\n",
      "std         1.732045       1.730417       3.473445      44.749921\n",
      "min        -8.760004      -7.084020     -11.970335       0.000000\n",
      "25%        -1.162288      -1.174820       0.130359      59.450441\n",
      "50%         0.009424      -0.009482       2.484236      94.925613\n",
      "75%         1.158535       1.163678       4.858794     130.595027\n",
      "max         7.238262       7.844801      16.739402     190.029838\n"
     ]
    }
   ],
   "source": [
    "print(gd0.describe())\n",
    "print()\n",
    "print(gd1.describe())\n",
    "print()\n",
    "print(gd2.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Выводим описательную статистику по каждому региону"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и проверка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    features = data.drop(['product','id'], axis=1)\n",
    "    target = data['product']\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25,\n",
    "                                                                                  random_state=17)\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    scaler = MinMaxScaler()\n",
    "    features_train = scaler.fit_transform(features_train)\n",
    "    features_valid = scaler.transform(features_valid)\n",
    "    \n",
    "    lr = LinearRegression(normalize=False)\n",
    "    lr.fit(features_train, target_train)\n",
    "    predictions = lr.predict(features_valid)\n",
    "    predictions = pd.Series(predictions)\n",
    "    \n",
    "    rmse = (mean_squared_error(predictions, target_valid))**(0.5)\n",
    "    average_product = sum(predictions) / len(predictions)\n",
    "    \n",
    "    print('RMSE: {0:.2f}'.format(rmse))\n",
    "    print('Кол-во нефти в среднем: {0:.2f}'.format(average_product))\n",
    "    return (predictions, target_valid.reset_index(drop=True), rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем функцию `split` которая:\n",
    "1. Делит выборку на валидационнцю и обучающую\n",
    "2. Скалирует данные\n",
    "3. Обучает модель на основе подготовленных данных\n",
    "4. Высчитывает `predictions`\n",
    "5. Находит `RMSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_data_0\n",
      "RMSE: 37.79\n",
      "Кол-во нефти в среднем: 92.39\n",
      "\n",
      "geo_data_1\n",
      "RMSE: 0.89\n",
      "Кол-во нефти в среднем: 68.82\n",
      "\n",
      "geo_data_2\n",
      "RMSE: 40.14\n",
      "Кол-во нефти в среднем: 95.09\n"
     ]
    }
   ],
   "source": [
    "print('geo_data_0')\n",
    "predict_0, valid_0, rmse_0 = split(gd0)\n",
    "print()\n",
    "\n",
    "print('geo_data_1')\n",
    "predict_1, valid_1, rmse_1 = split(gd1)\n",
    "\n",
    "print()\n",
    "print('geo_data_2')\n",
    "predict_2, valid_2, rmse_2 = split(gd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Записываем полученные данные в переменные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка к расчёту прибыли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точка безубыточности: 22222 тыс. баррелей\n",
      "Средний объем нефти для 1 скважины для выхода на ТБ: 112.0\n"
     ]
    }
   ],
   "source": [
    "total_budget = 10**10 \n",
    "income_per_barrel = 450 * 10**3\n",
    "\n",
    "break_even = total_budget / income_per_barrel\n",
    "print('Точка безубыточности:', round(break_even), 'тыс. баррелей')\n",
    "print('Средний объем нефти для 1 скважины для выхода на ТБ:', np.ceil(break_even/200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Задаем переменные и присваиваем им значения\n",
    "- Высчитываем ТБ(точку безубыточности)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчёт прибыли и рисков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit_func(predictions, target):\n",
    "    top_predictions = predictions.sort_values(ascending=False)\n",
    "    top_target = target[top_predictions.index][:200]\n",
    "    revenue = top_target.sum() * income_per_barrel\n",
    "    return revenue - total_budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Пишем функцию которая расчитывает прибыль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.RandomState(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_risk(predictions, target):\n",
    "    revenue = []\n",
    "    \n",
    "    for i in range(1000):\n",
    "        target_sample = target.sample(500, replace=True, random_state=state)\n",
    "        predictions_sample = predictions[target_sample.index]\n",
    "        revenue.append(profit_func(predictions_sample, target_sample))\n",
    "        \n",
    "    lower = int(np.percentile(revenue, 2.5))\n",
    "    higher = int(np.percentile(revenue, 97.5))\n",
    "    mean_revenue = int(sum(revenue) / len(revenue))\n",
    "    risk = st.percentileofscore(revenue, 0)\n",
    "\n",
    "    return ((lower, higher), mean_revenue, risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Пишем функцию которая расчитывае доверительный интервал и риск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Регион: geo data 0\n",
      "Среднее: 471268306\n",
      "95% доверительный интервал: (-65729586, 986488701)\n",
      "Риск: 4.6000000000000005 %\n",
      "\n",
      "Регион: geo data 1\n",
      "Среднее: 494222368\n",
      "95% доверительный интервал: (77802011, 913637149)\n",
      "Риск: 1.1 %\n",
      "\n",
      "Регион: geo data 2\n",
      "Среднее: 352922017\n",
      "95% доверительный интервал: (-187223101, 876785878)\n",
      "Риск: 10.600000000000001 %\n",
      "\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 0\n",
    "for predictions, targets in zip([predict_0, predict_1, predict_2], \n",
    "                         [valid_0, valid_1, valid_2]):\n",
    "    interval, mean_revenue, risk = confidence_risk(predictions, targets)\n",
    "    print('Регион: geo data', i)\n",
    "    i += 1\n",
    "    print('Среднее:', mean_revenue)\n",
    "    print('95% доверительный интервал:', interval)\n",
    "    print('Риск:', risk,'%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Автоматизируем присваивание функции по регионам, чтобы было быстрее посчитать все."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В самом начале мы подготовили данные для анализа, изучили их типы, проверили на наличие дубликатов, вывели описательную статистику по каждому региону.\n",
    "- Затем была написана функция, которая разбивает данные на выборки, скалирует их, строит модель линейной регрессии для того, что предсказать объемы нефти в каждой из скважин.\n",
    "- Далее, с помощью `Bootstrap` был найден 95% доверительный интервал. \n",
    "- Наименее рискованным является второй регион, где риск составил 1.1%, средняя прибыль также является наибольшей для второго региона.\n",
    "- С точки зрения перспектив разработки, наиболее привлекательным является второй регион."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
